### 机器学习(毕建东/刘扬)
##### 教材
黑皮书 《机器学习》 Mitchell，机械工业出版社
##### 复习范围
PPT大部分内容，第三、九、十、十一、十二章不在考试范围。需要掌握所有涉及算法的流程、计算、应用、存在的不足和改进的方法，对于梯度下降、模式理论和Q学习的收敛性需要掌握证明。
##### 需掌握的算法
候选消除算法、GS、AQ、ID3、FIND-S、梯度下降算法、遗传算法、KNN、FOIL、Q学习、最小属性子集算法、PCA、Kmeans、GMM、EM
##### 考题回忆
考了候选消除算法的计算、GS算法的计算和默写、Q学习的收敛性证明、Kmeans的流程以及它和GMM的联系、梯度下降算法的流程、遗传算法的流程、概念学习的归纳偏执(对于无偏和有偏的学习器，假设空间分别有多少个假设，如书P29的推导)
##### 复习建议
考的比较简单，但需要复习得很细致，建议至少对着PPT跟着书看一遍、刷一遍往年题，考试题基本和往年类似。如果是单纯应付考试，EM这种大BOSS可以少花些精力，它的推导和计算明显考不了，最多考算法流程，你可以死记。另外，记算法的时候应多动笔默写，多看它相关的应用实例加深理解，当时考试结束后周围同学不少吐槽算法没完全记住。
##### 实验
机器学习相关算法均可，但需要自己实现或改进，不可使用TensorFlow、Pytorch这样的框架。
##### PS
平时课能去就去，毕老师讲的比较通俗，跟着听课能在复习的时候节省不少力气，后面刘扬老师讲的几节课浓缩得很厉害，比较难，不要被吓到。顺便，不得不吐槽教材教材，编写不是很好，比如反向传播的推导，Mitchell将不同层的权重都用Wij表示了，完全区分不开，这部分写的还不如上面模式识别的教材，真是全靠同行衬托啊，它的内容也有些过时。对比本科的时候旁听的刘扬老师的机器学习，硕士的机器学习简单了不少，最直白的就是实验内容，当时他们本科有4个实验，都是常用而且较难的算法。这也就意味着，如果想要从事ML开发和研究，除了这门课，还需要自己补很多内容。
